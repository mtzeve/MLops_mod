{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/693399\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import hopsworks\n",
    "import hsfs\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler  # Import StandardScaler from scikit-learn\n",
    "import joblib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Connecting to hopsworks\n",
    "api_key = os.environ.get('hopsworks_api')\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "#Another connection to hopsworks\n",
    "api_key = os.getenv('hopsworks_api')\n",
    "connection = hsfs.connection()\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='tesla_stocks_fv',\n",
    "    version=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up train & test split dates\n",
    "train_start = \"2022-06-22\"\n",
    "train_end = \"2023-12-31\"\n",
    "\n",
    "test_start = '2024-01-01'\n",
    "test_end = \"2024-05-08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/693399/jobs/named/tesla_stocks_fv_3_create_fv_td_09052024115807/executions\n",
      "2024-05-09 13:59:23,623 WARNING: VersionWarning: Incremented version to `2`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, <hsfs.core.job.Job at 0x233d2bfb990>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the train/test split on the feature view with the split dates\n",
    "feature_view.create_train_test_split(\n",
    "    train_start=train_start,\n",
    "    train_end=train_end,\n",
    "    test_start=test_start,\n",
    "    test_end=test_end,\n",
    "    data_format='csv',\n",
    "    coalesce= True,\n",
    "    statistics_config={'histogram':True,'correlations':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the split from feature view\n",
    "X_train, X_test, y_train, y_test = feature_view.get_train_test_split(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-14T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.046415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-21T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.096789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-17T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.145765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-16T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.094337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-28T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.145765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2023-02-10T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.096789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2023-05-08T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>-0.006389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2022-09-08T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.094337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023-07-06T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.174215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023-10-27T00:00:00.000Z</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.031260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date ticker  sentiment\n",
       "0    2022-12-14T00:00:00.000Z   TSLA   0.046415\n",
       "1    2023-02-21T00:00:00.000Z   TSLA   0.096789\n",
       "2    2023-08-17T00:00:00.000Z   TSLA   0.145765\n",
       "3    2022-09-16T00:00:00.000Z   TSLA   0.094337\n",
       "4    2023-08-28T00:00:00.000Z   TSLA   0.145765\n",
       "..                        ...    ...        ...\n",
       "377  2023-02-10T00:00:00.000Z   TSLA   0.096789\n",
       "378  2023-05-08T00:00:00.000Z   TSLA  -0.006389\n",
       "379  2022-09-08T00:00:00.000Z   TSLA   0.094337\n",
       "380  2023-07-06T00:00:00.000Z   TSLA   0.174215\n",
       "381  2023-10-27T00:00:00.000Z   TSLA   0.031260\n",
       "\n",
       "[382 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date into datetime\n",
    "X_train['date'] = pd.to_datetime(X_train['date']).dt.date\n",
    "X_test['date'] = pd.to_datetime(X_test['date']).dt.date\n",
    "X_train['date'] = pd.to_datetime(X_train['date'])\n",
    "X_test['date'] = pd.to_datetime(X_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.046415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.096789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.145765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.094337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.145765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  sentiment\n",
       "0 2022-12-14   TSLA   0.046415\n",
       "1 2023-02-21   TSLA   0.096789\n",
       "2 2023-08-17   TSLA   0.145765\n",
       "3 2022-09-16   TSLA   0.094337\n",
       "4 2023-08-28   TSLA   0.145765"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'ticker' column\n",
    "tickers = X_train[['ticker']]\n",
    "\n",
    "# Initializing OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the 'ticker' column\n",
    "ticker_encoded = encoder.fit_transform(tickers)\n",
    "\n",
    "# Converting the encoded column into a DataFrame\n",
    "ticker_encoded_df = pd.DataFrame(ticker_encoded.toarray(), columns=encoder.get_feature_names_out(['ticker']))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "X_train = pd.concat([X_train, ticker_encoded_df], axis=1)\n",
    "\n",
    "# Dropping the original 'ticker' column\n",
    "X_train.drop('ticker', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ticker_TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>0.046415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>0.096789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>0.145765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>0.094337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.145765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sentiment  ticker_TSLA\n",
       "0 2022-12-14   0.046415          1.0\n",
       "1 2023-02-21   0.096789          1.0\n",
       "2 2023-08-17   0.145765          1.0\n",
       "3 2022-09-16   0.094337          1.0\n",
       "4 2023-08-28   0.145765          1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting X train after onehotencoding 'Ticker'\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['ticker'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Doing the same for X test as done to X train\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tickers \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initializing OneHotEncoder\u001b[39;00m\n\u001b[0;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n",
      "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Dokumenter\\Master\\MLops\\MLops_mod-2\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3809\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3810\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Dokumenter\\Master\\MLops\\MLops_mod-2\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6113\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6115\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Dokumenter\\Master\\MLops\\MLops_mod-2\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6170\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6173\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['ticker'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#Doing the same for X test as done to X train\n",
    "\n",
    "tickers = X_test[['ticker']]\n",
    "\n",
    "# Initializing OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the 'ticker' column\n",
    "ticker_encoded_test = encoder.fit_transform(tickers)\n",
    "\n",
    "# Converting the encoded column into a DataFrame\n",
    "ticker_encoded_df_test = pd.DataFrame(ticker_encoded_test.toarray(), columns=encoder.get_feature_names_out(['ticker']))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "X_test = pd.concat([X_test, ticker_encoded_df_test], axis=1)\n",
    "\n",
    "# Dropping the original 'ticker' column\n",
    "X_test.drop('ticker', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in MinMaxScaler to be used on the target variable 'open'\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting and transforming the 'open' column\n",
    "y_train['open_scaled'] = scaler.fit_transform(y_train[['open']])\n",
    "y_train.drop('open', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same to y_test as done to y_train \n",
    "y_test['open_scaled'] = scaler.fit_transform(y_test[['open']])\n",
    "y_test.drop('open', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function for the LSTM model\n",
    "def create_model(input_shape,\n",
    "                 LSTM_filters=64,\n",
    "                 dropout=0.1,\n",
    "                 recurrent_dropout=0.1,\n",
    "                 dense_dropout=0.5,\n",
    "                 activation='relu',\n",
    "                 depth=1):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    if depth > 1:\n",
    "        for i in range(1, depth):\n",
    "            # Recurrent layer\n",
    "            model.add(LSTM(LSTM_filters, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "\n",
    "    # Recurrent layer\n",
    "    model.add(LSTM(LSTM_filters, return_sequences=False, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "\n",
    "    # Fully connected layer\n",
    "    if activation == 'relu':\n",
    "        model.add(Dense(LSTM_filters, activation='relu'))\n",
    "    elif activation == 'leaky_relu':\n",
    "        model.add(Dense(LSTM_filters))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "    # Dropout for regularization\n",
    "    model.add(Dropout(dense_dropout))\n",
    "\n",
    "    # Output layer for predicting one day forward\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:00:56,030 WARNING: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As X_train['date'] column exists and is in datetime format, we're converting it\n",
    "X_train['year'] = X_train['date'].dt.year\n",
    "X_train['month'] = X_train['date'].dt.month\n",
    "X_train['day'] = X_train['date'].dt.day\n",
    "\n",
    "# Dropping the original date column\n",
    "X_train.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "\n",
    "# Reshaping the array to have a shape suitable for LSTM\n",
    "X_train_array = np.expand_dims(X_train_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.values\n",
    "\n",
    "# Reshaping X_train_array to add a time step dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], 1, X_train_array.shape[1])\n",
    "\n",
    "# Assuming X_train_reshaped shape is now (374, 1, 5)\n",
    "input_shape = X_train_reshaped.shape[1:]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 108939.8047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x233d40d2ed0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model on the training dataset\n",
    "model.fit(X_train_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:01:11,178 WARNING: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As X_test['date'] column exists and is in datetime format, we're converting it\n",
    "X_test['year'] = X_test['date'].dt.year\n",
    "X_test['month'] = X_test['date'].dt.month\n",
    "X_test['day'] = X_test['date'].dt.day\n",
    "\n",
    "# Dropping the original date column\n",
    "X_test.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the array to have a shape suitable for LSTM\n",
    "X_test_array = np.expand_dims(X_test_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step\n",
      "Root Mean Squared Error (RMSE): 187.9560407085387\n"
     ]
    }
   ],
   "source": [
    "# Predicting y_pred with X_test\n",
    "y_pred = model.predict(X_test_array)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "#Conneting to hopsworks model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 187.9560407085387}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute RMSE metric for filling the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_metrics = {\"RMSE\": rmse}\n",
    "rmse_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the model schema\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a file colled 'stock_model'\n",
    "model_dir=\"stock_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6169babeb154f54bdbb9b0b490333ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5749cebd1fe422dbeaba0ec2718a3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/561 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/693399/models/stock_pred_model/6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'stock_pred_model', version: 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model to hopsworks model registry\n",
    "#stock_pred_model = mr.tensorflow.create_model(\n",
    "#        name=\"stock_pred_model\",\n",
    "#        metrics= rmse_metrics,\n",
    "#        model_schema=model_schema,\n",
    "#        description=\"Stock Market TSLA Predictor from News Sentiment\",\n",
    "#    )\n",
    "\n",
    "#stock_pred_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf26bb1758d4f8cb909746f10161447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48adeee244764944875c4a653b831c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/291263 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:01:42,684 WARNING: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71f4da81bf34459919c850d615ef04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/44 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44da8c79c3664fba963b44886f30ea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/554 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/693399/models/stock_pred_model/11\n"
     ]
    }
   ],
   "source": [
    "def register_tensorflow_model(model, name, description, features, labels, metrics):\n",
    "    from hsml.schema import Schema\n",
    "    from hsml.model_schema import ModelSchema\n",
    "    import os\n",
    "    import joblib\n",
    "    import shutil\n",
    "\n",
    "    mr = project.get_model_registry()\n",
    "\n",
    "    model_dir= name + \"_model\"\n",
    "    if os.path.isdir(model_dir) == False:\n",
    "        os.mkdir(model_dir)\n",
    "    pickle= name + '_model.pkl'\n",
    "    # This will strip out the sml directory, copying only the files\n",
    "    #shutil.copytree(\"sml\", model_dir, dirs_exist_ok=True) #python 3.8+\n",
    "\n",
    "    joblib.dump(model, model_dir + \"/\" + pickle)\n",
    "\n",
    "    input_example = features.sample()\n",
    "    input_schema = Schema(features)\n",
    "    output_schema = Schema(labels)\n",
    "    model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "    stock_pred_model = mr.tensorflow.create_model(\n",
    "        name=\"stock_pred_model\", \n",
    "        metrics=rmse_metrics,\n",
    "        model_schema=model_schema,\n",
    "        input_example=input_example, \n",
    "        description=description)\n",
    "\n",
    "    # Save all artifacts in the model directory to the model registry\n",
    "    stock_pred_model.save(model_dir)\n",
    "\n",
    "\n",
    "register_tensorflow_model(model, \"stock_prediction\", \"Stock Prediction\", X_train, y_train, rmse_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
